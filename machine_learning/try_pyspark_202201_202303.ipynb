{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7448d249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: int, year: int, month: int, day: int, hour: int, PULocationID: int, weekday: int, count: int, lat: double, lon: double, countN: double]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import time\n",
    "import datetime\n",
    "# from pyspark.sql.types import IntegerType\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MySparkSession\") \\\n",
    "                            .config(\"spark.master\", \"local[10]\") \\\n",
    "                            .config(\"spark.driver.cores\", \"1\") \\\n",
    "                            .config(\"spark.driver.memory\", \"1g\") \\\n",
    "                            .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "                            .config(\"spark.memory.offHeap.size\", \"1g\") \\\n",
    "                            .getOrCreate()\n",
    "\n",
    "\n",
    "df = spark.read.parquet('../time_series/TS6/TS6-201902_202306.parquet')\n",
    "df = df.drop(\"is_holiday\", 'TempTime', '__index_level_0__')\n",
    "df = df.repartition(4)\n",
    "mapping = {'yellow': 1, \n",
    "           'lyft': 2, \n",
    "           'uber': 3}\n",
    "\n",
    "for key, value in mapping.items():\n",
    "    df = df.withColumn(\"Name\", when(df[\"Name\"] == key, value).otherwise(df[\"Name\"]))\n",
    "\n",
    "\n",
    "for c in ['Name', 'year', 'month', 'day', 'hour', 'PULocationID']:\n",
    "    df = df.withColumn(c, col(c).cast('integer'))\n",
    "feature_variables = df.drop('count', 'countN')\n",
    "\n",
    "inputcols = feature_variables.columns\n",
    "\n",
    "assembler = VectorAssembler(inputCols=inputcols, outputCol=\"features\")\n",
    "\n",
    "df_valid = df.filter((col(\"year\") == 2023) & (col(\"month\") > 3))\n",
    "\n",
    "\n",
    "df.filter(\n",
    "    (col(\"year\") == 2022) |\n",
    "    ((col(\"year\") == 2023) & (col(\"month\") <= 3))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "038302a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assembler.transform(df)\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "scaled_data = scaler.fit(output).transform(output)\n",
    "\n",
    "scaled_data.select('scaled_features', 'countN')\n",
    "\n",
    "final_data = scaled_data.select('scaled_features', 'countN')\n",
    "\n",
    "train, test = final_data.randomSplit([0.9, 0.1], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f59fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start時間: 2023-09-20 00:37:07.490677\n",
      "執行時間: 29352.56973004341 秒\n"
     ]
    }
   ],
   "source": [
    "print(\"start時間:\", datetime.datetime.now())\n",
    "start_time = time.time()\n",
    "\n",
    "gbtr = GBTRegressor(featuresCol='scaled_features', labelCol='countN', maxDepth=10, maxIter=100, stepSize=0.1, subsamplingRate=0.8, cacheNodeIds=True, seed=1, maxMemoryInMB=10240, maxBins=64)\n",
    "\n",
    "gbtr_model = gbtr.fit(train)\n",
    "\n",
    "y_pred = gbtr_model.transform(test)\n",
    "\n",
    "y_pred.select('countN', 'prediction')\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(\"執行時間:\", execution_time, \"秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4676e0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.950129150365152\n",
      "MAE: 6.912925560613276\n",
      "RMSE: 13.809608929684389\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='countN')\n",
    "\n",
    "r2 = evaluator.evaluate(y_pred, {evaluator.metricName: 'r2'})\n",
    "mae = evaluator.evaluate(y_pred, {evaluator.metricName: 'mae'})\n",
    "rmse = evaluator.evaluate(y_pred, {evaluator.metricName: 'rmse'})\n",
    "\n",
    "print(f'R2: {r2}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fee6913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.7138127726500585\n",
      "MAE: 16.040662946842154\n",
      "RMSE: 35.51617972982376\n"
     ]
    }
   ],
   "source": [
    "output_df_valid = assembler.transform(df_valid)\n",
    "\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "scaled_data = scaler.fit(output_df_valid).transform(output_df_valid)\n",
    "\n",
    "valid_data = scaled_data.select('scaled_features', 'count')\n",
    "\n",
    "\n",
    "\n",
    "y_pred_2023 = gbtr_model.transform(valid_data)\n",
    "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='count')\n",
    "\n",
    "r2 = evaluator.evaluate(y_pred_2023, {evaluator.metricName: 'r2'})\n",
    "mae = evaluator.evaluate(y_pred_2023, {evaluator.metricName: 'mae'})\n",
    "rmse = evaluator.evaluate(y_pred_2023, {evaluator.metricName: 'rmse'})\n",
    "\n",
    "print(f'R2: {r2}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1329ce50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

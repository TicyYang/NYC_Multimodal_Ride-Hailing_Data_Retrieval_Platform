{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bce9b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+---+----+------------+-------+----------+-----+-----------+------------+-------------------+------------------+-----------------+\n",
      "|Name|year|month|day|hour|PULocationID|weekday|is_holiday|count|        lat|         lon|           TempTime|            countN|__index_level_0__|\n",
      "+----+----+-----+---+----+------------+-------+----------+-----+-----------+------------+-------------------+------------------+-----------------+\n",
      "|lyft|2022|    1|  1|   0|           3|      5|      true|   16|40.86429404|-73.84650986|2022-01-01 00:00:00|16.666666666666668|         20013480|\n",
      "|lyft|2022|    1|  1|   1|           3|      5|      true|   21|40.86429404|-73.84650986|2022-01-01 01:00:00|              14.0|         20013481|\n",
      "|lyft|2022|    1|  1|   2|           3|      5|      true|    6|40.86429404|-73.84650986|2022-01-01 02:00:00| 6.666666666666667|         20013482|\n",
      "|lyft|2022|    1|  1|   3|           3|      5|      true|   11|40.86429404|-73.84650986|2022-01-01 03:00:00| 6.333333333333333|         20013483|\n",
      "|lyft|2022|    1|  1|   4|           3|      5|      true|   10|40.86429404|-73.84650986|2022-01-01 04:00:00| 6.333333333333333|         20013484|\n",
      "|lyft|2022|    1|  1|   5|           3|      5|      true|    7|40.86429404|-73.84650986|2022-01-01 05:00:00| 5.333333333333333|         20013485|\n",
      "|lyft|2022|    1|  1|   6|           3|      5|      true|    9|40.86429404|-73.84650986|2022-01-01 06:00:00|               6.0|         20013486|\n",
      "|lyft|2022|    1|  1|   7|           3|      5|      true|    6|40.86429404|-73.84650986|2022-01-01 07:00:00| 4.666666666666667|         20013487|\n",
      "|lyft|2022|    1|  1|   8|           3|      5|      true|    5|40.86429404|-73.84650986|2022-01-01 08:00:00| 7.666666666666667|         20013488|\n",
      "|lyft|2022|    1|  1|   9|           3|      5|      true|    7|40.86429404|-73.84650986|2022-01-01 09:00:00|               9.0|         20013489|\n",
      "+----+----+-----+---+----+------------+-------+----------+-----+-----------+------------+-------------------+------------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6859080"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StandardScaler, MinMaxScaler\n",
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MySparkSession\") \\\n",
    "                            .config(\"spark.executor.memory\", \"36g\") \\\n",
    "                            .config(\"spark.memory.offHeap.enabled\", \"true\") \\\n",
    "                            .config(\"spark.memory.offHeap.size\", \"3g\") \\\n",
    "                            .getOrCreate()\n",
    "\n",
    "\n",
    "df = spark.read.parquet('../time_series/TS6/TS6-2022.parquet')\n",
    "df.show(10)\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4883365d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+---+----+------------+-------+-----+-----------+------------+------------------+\n",
      "|Name|year|month|day|hour|PULocationID|weekday|count|        lat|         lon|            countN|\n",
      "+----+----+-----+---+----+------------+-------+-----+-----------+------------+------------------+\n",
      "|lyft|2022|    1|  1|   0|           3|      5|   16|40.86429404|-73.84650986|16.666666666666668|\n",
      "|lyft|2022|    1|  1|   1|           3|      5|   21|40.86429404|-73.84650986|              14.0|\n",
      "|lyft|2022|    1|  1|   2|           3|      5|    6|40.86429404|-73.84650986| 6.666666666666667|\n",
      "|lyft|2022|    1|  1|   3|           3|      5|   11|40.86429404|-73.84650986| 6.333333333333333|\n",
      "|lyft|2022|    1|  1|   4|           3|      5|   10|40.86429404|-73.84650986| 6.333333333333333|\n",
      "|lyft|2022|    1|  1|   5|           3|      5|    7|40.86429404|-73.84650986| 5.333333333333333|\n",
      "|lyft|2022|    1|  1|   6|           3|      5|    9|40.86429404|-73.84650986|               6.0|\n",
      "|lyft|2022|    1|  1|   7|           3|      5|    6|40.86429404|-73.84650986| 4.666666666666667|\n",
      "|lyft|2022|    1|  1|   8|           3|      5|    5|40.86429404|-73.84650986| 7.666666666666667|\n",
      "|lyft|2022|    1|  1|   9|           3|      5|    7|40.86429404|-73.84650986|               9.0|\n",
      "+----+----+-----+---+----+------------+-------+-----+-----------+------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop('is_holiday', 'TempTime', '__index_level_0__')\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "944b8194",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df = df.withColumn(\"is_holiday\", col(\"is_holiday\").cast(\"int\"))\n",
    "# df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3d41cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- countN: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "mapping = {'yellow': 1, \n",
    "           'lyft': 2, \n",
    "           'uber': 3}\n",
    "\n",
    "for key, value in mapping.items():\n",
    "    df = df.withColumn(\"Name\", when(df[\"Name\"] == key, value).otherwise(df[\"Name\"]))\n",
    "\n",
    "\n",
    "for c in ['Name', 'year', 'month', 'day', 'hour', 'PULocationID']:\n",
    "    df = df.withColumn(c, col(c).cast('integer'))\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4458b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of rows: 6859080\n",
      "Num of columns: 11\n"
     ]
    }
   ],
   "source": [
    "print(f'Num of rows: {df.count()}')\n",
    "print(f'Num of columns: {len(df.columns)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fd42c6",
   "metadata": {},
   "source": [
    "讀入df1並進行與df相同的處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45508e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- weekday: integer (nullable = true)\n",
      " |-- count: integer (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- countN: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.read.parquet('../time_series/TS6/TS6-2023.parquet')\n",
    "df1 = df1.drop('is_holiday', 'TempTime', '__index_level_0__')\n",
    "\n",
    "# df1 = df1.withColumn(\"is_holiday\", col(\"is_holiday\").cast(\"integer\"))\n",
    "\n",
    "mapping = {'yellow': 1, \n",
    "           'lyft': 2, \n",
    "           'uber': 3}\n",
    "\n",
    "for key, value in mapping.items():\n",
    "    df1 = df1.withColumn(\"Name\", when(df1[\"Name\"] == key, value).otherwise(df1[\"Name\"]))\n",
    "\n",
    "\n",
    "for c in ['Name', 'year', 'month', 'day', 'hour', 'PULocationID']:\n",
    "    df1 = df1.withColumn(c, col(c).cast('integer'))\n",
    "\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a62cac4",
   "metadata": {},
   "source": [
    "組合df的features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ca7b9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+-----+---+----+------------+-------+-----+-----------+------------+------------------+--------------------+\n",
      "|Name|year|month|day|hour|PULocationID|weekday|count|        lat|         lon|            countN|            features|\n",
      "+----+----+-----+---+----+------------+-------+-----+-----------+------------+------------------+--------------------+\n",
      "|   2|2022|    1|  1|   0|           3|      5|   16|40.86429404|-73.84650986|16.666666666666668|[2.0,2022.0,1.0,1...|\n",
      "|   2|2022|    1|  1|   1|           3|      5|   21|40.86429404|-73.84650986|              14.0|[2.0,2022.0,1.0,1...|\n",
      "|   2|2022|    1|  1|   2|           3|      5|    6|40.86429404|-73.84650986| 6.666666666666667|[2.0,2022.0,1.0,1...|\n",
      "|   2|2022|    1|  1|   3|           3|      5|   11|40.86429404|-73.84650986| 6.333333333333333|[2.0,2022.0,1.0,1...|\n",
      "|   2|2022|    1|  1|   4|           3|      5|   10|40.86429404|-73.84650986| 6.333333333333333|[2.0,2022.0,1.0,1...|\n",
      "|   2|2022|    1|  1|   5|           3|      5|    7|40.86429404|-73.84650986| 5.333333333333333|[2.0,2022.0,1.0,1...|\n",
      "|   2|2022|    1|  1|   6|           3|      5|    9|40.86429404|-73.84650986|               6.0|[2.0,2022.0,1.0,1...|\n",
      "|   2|2022|    1|  1|   7|           3|      5|    6|40.86429404|-73.84650986| 4.666666666666667|[2.0,2022.0,1.0,1...|\n",
      "|   2|2022|    1|  1|   8|           3|      5|    5|40.86429404|-73.84650986| 7.666666666666667|[2.0,2022.0,1.0,1...|\n",
      "|   2|2022|    1|  1|   9|           3|      5|    7|40.86429404|-73.84650986|               9.0|[2.0,2022.0,1.0,1...|\n",
      "+----+----+-----+---+----+------------+-------+-----+-----------+------------+------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_variables = df.drop('count', 'countN')\n",
    "inputcols = feature_variables.columns\n",
    "\n",
    "assembler = VectorAssembler(inputCols=inputcols, outputCol=\"features\")\n",
    "\n",
    "output = assembler.transform(df)\n",
    "output.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9415fb08",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|     scaled_features|            countN|\n",
      "+--------------------+------------------+\n",
      "|[2.44948956422488...|16.666666666666668|\n",
      "|[2.44948956422488...|              14.0|\n",
      "|[2.44948956422488...| 6.666666666666667|\n",
      "|[2.44948956422488...| 6.333333333333333|\n",
      "|[2.44948956422488...| 6.333333333333333|\n",
      "|[2.44948956422488...| 5.333333333333333|\n",
      "|[2.44948956422488...|               6.0|\n",
      "|[2.44948956422488...| 4.666666666666667|\n",
      "|[2.44948956422488...| 7.666666666666667|\n",
      "|[2.44948956422488...|               9.0|\n",
      "|[2.44948956422488...| 6.333333333333333|\n",
      "|[2.44948956422488...| 5.666666666666667|\n",
      "|[2.44948956422488...|10.333333333333334|\n",
      "|[2.44948956422488...|10.333333333333334|\n",
      "|[2.44948956422488...|11.666666666666666|\n",
      "|[2.44948956422488...|14.666666666666666|\n",
      "|[2.44948956422488...|12.666666666666666|\n",
      "|[2.44948956422488...|              15.0|\n",
      "|[2.44948956422488...|14.666666666666666|\n",
      "|[2.44948956422488...|              10.0|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "scaled_data = scaler.fit(output).transform(output)\n",
    "scaled_data.select('scaled_features', 'countN').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29f9a9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|            countN|\n",
      "+-------+------------------+\n",
      "|  count|           4801765|\n",
      "|   mean| 36.57626483872736|\n",
      "| stddev| 60.77862073991568|\n",
      "|    min|               0.0|\n",
      "|    max|1470.3333333333333|\n",
      "+-------+------------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|            countN|\n",
      "+-------+------------------+\n",
      "|  count|           2057315|\n",
      "|   mean|36.584410586937835|\n",
      "| stddev|60.854773873657706|\n",
      "|    min|               0.0|\n",
      "|    max|1476.3333333333333|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data = scaled_data.select('scaled_features', 'countN')\n",
    "\n",
    "train, test = final_data.randomSplit([0.7, 0.3])\n",
    "\n",
    "train.describe().show()\n",
    "test.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f720897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 4801765\n",
      "Test : 2057315\n"
     ]
    }
   ],
   "source": [
    "print(f'Train: {train.count()}')\n",
    "print(f'Test : {test.count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9220f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+\n",
      "|            countN|          prediction|\n",
      "+------------------+--------------------+\n",
      "|               0.0|    1.53787650236351|\n",
      "|               0.0|  0.6970397935382844|\n",
      "|               0.0|-0.03441223401360405|\n",
      "|               0.0|  0.5868512963445633|\n",
      "|               0.0|   0.531348351258214|\n",
      "|               0.0|  1.2946898460784817|\n",
      "|2.6666666666666665|  3.4618174252622618|\n",
      "|               0.0|-0.32433369090728265|\n",
      "|               0.0| 0.22021831372952572|\n",
      "|               0.0|    -5.4551571267528|\n",
      "+------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "執行時間: 9388.456265926361 秒\n"
     ]
    }
   ],
   "source": [
    "print(\"start時間:\", datetime.datetime.now())\n",
    "start_time = time.time()\n",
    "\n",
    "gbtr = GBTRegressor(featuresCol='scaled_features', labelCol='countN', \n",
    "                    maxDepth=10, maxIter=100, stepSize=0.1, \n",
    "                    cacheNodeIds=True, subsamplingRate=0.8, seed=42, maxMemoryInMB=10240)\n",
    "\n",
    "gbtr_model = gbtr.fit(train)\n",
    "\n",
    "y_pred = gbtr_model.transform(test)\n",
    "\n",
    "y_pred.select('countN', 'prediction').show(10)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(\"執行時間:\", execution_time, \"秒\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03a2ff76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.9723282548874154\n",
      "MAE: 5.3419144244341865\n",
      "RMSE: 10.123083562062549\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='countN')\n",
    "\n",
    "r2 = evaluator.evaluate(y_pred, {evaluator.metricName: 'r2'})\n",
    "mae = evaluator.evaluate(y_pred, {evaluator.metricName: 'mae'})\n",
    "rmse = evaluator.evaluate(y_pred, {evaluator.metricName: 'rmse'})\n",
    "\n",
    "print(f'R2: {r2}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84b7891",
   "metadata": {},
   "source": [
    "# 驗證集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "777991b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------------------+\n",
      "|     scaled_features|count|        prediction|\n",
      "+--------------------+-----+------------------+\n",
      "|[2.44948938270710...|   12|13.889402692274995|\n",
      "|[2.44948938270710...|   28|12.044515132291076|\n",
      "|[2.44948938270710...|   19| 5.626331337055775|\n",
      "|[2.44948938270710...|   26| 4.701026197754847|\n",
      "|[2.44948938270710...|   17| 5.441334966489215|\n",
      "+--------------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_variables = df1.drop('count', 'countN')\n",
    "inputcols = feature_variables.columns\n",
    "\n",
    "assembler = VectorAssembler(inputCols=inputcols, outputCol=\"features\")\n",
    "\n",
    "output = assembler.transform(df1)\n",
    "\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "scaled_data = scaler.fit(output).transform(output)\n",
    "\n",
    "valid_data = scaled_data.select('scaled_features', 'count')\n",
    "\n",
    "\n",
    "\n",
    "y_pred_2023 = gbtr_model.transform(valid_data)\n",
    "y_pred_2023.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e28ecbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.9240277583483465\n",
      "MAE: 8.579792656025745\n",
      "RMSE: 18.357343198180875\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='count')\n",
    "\n",
    "r2 = evaluator.evaluate(y_pred_2023, {evaluator.metricName: 'r2'})\n",
    "mae = evaluator.evaluate(y_pred_2023, {evaluator.metricName: 'mae'})\n",
    "rmse = evaluator.evaluate(y_pred_2023, {evaluator.metricName: 'rmse'})\n",
    "\n",
    "print(f'R2: {r2}')\n",
    "print(f'MAE: {mae}')\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6e2ac4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e833773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5046f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
